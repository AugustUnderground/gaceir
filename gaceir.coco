import coconut.convenience
import algorithm.ppo as ppo
#import algorithm.td3 as td3
import os, time, datetime
import torch as pt
import hace as ac
import gym, gace

## PPO
actor, critic = [ppo.run_episodes(e) for e in range(2)] |*> zip |> tuple
a, c = [ppo.run_episodes(e) for e in range(ppo.num_episodes)] |*> zip |> tuple

#states = ppo.envs.reset() |> fmap$pt.from_numpy |> pt.vstack |> .to(device)
#losses,rewards = ppo.run_episode(states, False, pt.empty(0), pt.empty(0))

## TD3
#models = [td3.run_episodes(e) for e in range(2)] |*> zip |> tuple
#models = [td3.run_episodes(e) for e in range(td3.num_episodes)] |*> zip |> tuple


