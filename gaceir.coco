import coconut.convenience
import os, time, datetime
import torch as pt
import hace as ac
import gym, gace
from hy.contrib.pprint import pp

## Environment setup
ace_id: str      = "op2"
ace_backend: str = "xh035"
ace_variant: int = 0
env_id: str      = f"gace:{ace_id}-{ace_backend}-v{ace_variant}"
num_envs: int    = 20 # 50
obs_dim: int     = 47
act_dim: int     = 10

envs: gace.envs.vec.VecACE = gace.vector_make_same(env_id, num_envs)
#obs_dim: int               = envs.observation_space[0].shape[0]
#act_dim: int               = envs.action_space[0].shape[0]
#obs_dim: int               = envs$[0].target |> len |> (*)$(3) |> (+)$(2)

## SAC
import algorithm.sac as sac
agent: sac.Agent = sac.make_agent act_dim obs_dim
acid = [sac.run_episode(agent, envs, eps) for eps in range(sac.num_episodes)] |*> zip |> tuple
#acid = [sac.run_episode(agent, envs, eps) for eps in range(2)] |*> zip |> tuple

## TD3
import algorithm.td3 as td3
agent: td3.Agent = td3.make_agent act_dim obs_dim
acid = [td3.run_episode(agent, envs, eps) for eps in range(td3.num_episodes)] |*> zip |> tuple
#acid = [td3.run_episode(agent, envs, eps) for eps in range(2)] |*> zip |> tuple

## PPO
import algorithm.ppo as ppo
agent: ppo.Agent = ppo.make_agent act_dim obs_dim
acid = [ppo.run_episode(agent, envs, eps) for eps in range(ppo.num_episodes)] |*> zip |> tuple
#acid = [ppo.run_episode(agent, envs, eps) for eps in range(2)] |*> zip |> tuple
